{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AutoSF.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"rzGcUhajO25L"},"source":["<center><h1>GDL - AutoSF</h1></center>\n","\n","In our project, we try to achieve state-of-the-art results in the ogbl-biokg dataset (https://ogb.stanford.edu/docs/leader_linkprop/#ogbl-biokg).<br/>\n","To do so, we rely on AutoSF by Zhang et. al.<br/>\n","<br/>\n","OGB: https://ogb.stanford.edu/<br/>\n","AutoSF Paper: https://arxiv.org/pdf/1904.11682.pdf <br/>\n","AutoSF Code: https://github.com/AutoML-4Paradigm/AutoSF<br/>\n","<br/>\n","<b>Authors: </b> <br/>\n","Michael Mazourik (mazoum@usi.ch)<br/>\n","Brian Pulfer: (pulfeb@usi.ch)"]},{"cell_type":"markdown","metadata":{"id":"Y1oPx86HPwv_"},"source":["# Installing OGB and cloning AutoSF repository"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vBzegKqMO3MT","executionInfo":{"status":"ok","timestamp":1621188950868,"user_tz":-120,"elapsed":8049,"user":{"displayName":"Michael M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXS5G7Y8XOsAM2o7_7xf4XI_nDPbq0GP_tO4_J7g=s64","userId":"08878956878756496165"}},"outputId":"88b3d868-8dc7-4d9e-9f1b-01eb887cd936"},"source":["!pip install ogb\n","!git clone https://github.com/AutoML-4Paradigm/AutoSF.git\n","%cd /content/AutoSF/"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: ogb in /usr/local/lib/python3.7/dist-packages (1.3.1)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.1.5)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.19.5)\n","Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (4.41.1)\n","Requirement already satisfied: outdated>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (0.2.1)\n","Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.24.3)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (0.22.2.post1)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.8.1+cu101)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.15.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2.8.1)\n","Requirement already satisfied: littleutils in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb) (0.2.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb) (2.23.0)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.0.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->ogb) (3.7.4.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2020.12.5)\n","Cloning into 'AutoSF'...\n","remote: Enumerating objects: 205, done.\u001b[K\n","remote: Counting objects: 100% (205/205), done.\u001b[K\n","remote: Compressing objects: 100% (155/155), done.\u001b[K\n","remote: Total 205 (delta 65), reused 172 (delta 44), pack-reused 0\u001b[K\n","Receiving objects: 100% (205/205), 43.81 MiB | 31.57 MiB/s, done.\n","Resolving deltas: 100% (65/65), done.\n","/content/AutoSF\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ujEg9hP0PBh0"},"source":["# Imports"]},{"cell_type":"code","metadata":{"id":"5GyHhP1qPBnc","executionInfo":{"status":"ok","timestamp":1621188950870,"user_tz":-120,"elapsed":8039,"user":{"displayName":"Michael M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXS5G7Y8XOsAM2o7_7xf4XI_nDPbq0GP_tO4_J7g=s64","userId":"08878956878756496165"}}},"source":["# CSV\n","import csv\n","\n","# NumPy\n","import numpy as np\n","\n","# Pandas\n","import pandas as pd\n","\n","# AutoSF DataLoader\n","from read_data import DataLoader\n","\n","# OGB\n","from ogb.linkproppred import Evaluator\n","from ogb.linkproppred.dataset import LinkPropPredDataset "],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JCxTGTMNPCF6"},"source":["# Loading Dataset\n","\n","We load the dataset as documented in the OGB website. We then use this dataset object to write the <i>entity2id.txt</i> and <i>relation2id.txt</i> files (which are standard in libraries like OpenKE). These files will then be read by the DataLoader implemented by Zhang et. al."]},{"cell_type":"code","metadata":{"id":"KpP38SIwH4j5","executionInfo":{"status":"ok","timestamp":1621188950870,"user_tz":-120,"elapsed":8033,"user":{"displayName":"Michael M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXS5G7Y8XOsAM2o7_7xf4XI_nDPbq0GP_tO4_J7g=s64","userId":"08878956878756496165"}}},"source":["def type_and_id_2_new_id(typ, id):\n","  base = 0\n","\n","  if 'dis' in typ:\n","    base += 0\n","  elif 'prot' in typ:\n","    base = 10_687\n","  elif 'drug' in typ:\n","    base = 10_687 + 17_499\n","  elif 'effe' in typ:\n","    base = 10_687 + 17_499 + 10_533\n","  elif 'fun' in typ:\n","    base = 10_687 + 17_499 + 10_533 + 9_969\n","\n","  return base + id\n","\n","def trainset_to_newset(train_set):\n","  tmp_set = []\n","\n","  for ht, h, r, tt, t in zip(train_set['head_type'], train_set['head'], train_set['relation'], train_set['tail_type'], train_set['tail']):\n","    head_id = type_and_id_2_new_id(ht, h)\n","    tail_id = type_and_id_2_new_id(tt, t)\n","  \n","    tmp_set.append([head_id, r, tail_id])\n","  \n","  return pd.DataFrame(np.array(tmp_set), columns=['head', 'relation', 'tail'])\n","\n","def valset_to_newset(val_set):\n","  tmp_set = []\n","\n","  for ht, h, nhs, r, tt, t, nts in zip(val_set['head_type'], val_set['head'], val_set['head_neg'], val_set['relation'], val_set['tail_type'], val_set['tail'], val_set['tail_neg']):\n","    h_id = type_and_id_2_new_id(ht, h)\n","    t_id = type_and_id_2_new_id(tt, t)\n","\n","    nh_ids, nt_ids = [], []\n","    for nh, nt in zip(nhs, nts):\n","      nh_id = type_and_id_2_new_id(ht, nh)\n","      nt_id = type_and_id_2_new_id(tt, nt)\n","\n","      nh_ids.append(nh_id)\n","      nt_ids.append(nt_id)\n","\n","    tmp_set.append([h_id, nh_ids, r, t_id, nt_ids])\n","  \n","  return pd.DataFrame(np.array(tmp_set), columns=['head', 'head_neg', 'relation', 'tail', 'tail_neg'])"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ug7_rfeTO8ja","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621189325275,"user_tz":-120,"elapsed":382430,"user":{"displayName":"Michael M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXS5G7Y8XOsAM2o7_7xf4XI_nDPbq0GP_tO4_J7g=s64","userId":"08878956878756496165"}},"outputId":"5e2bcf1d-3969-4070-be92-a5bdacb3571e"},"source":["# Loading OGB dataset\n","dataset = LinkPropPredDataset(name = 'ogbl-biokg') \n","\n","split_set = dataset.get_edge_split()\n","train_set, valid_set, test_set = split_set[\"train\"], split_set[\"valid\"], split_set[\"test\"]\n","\n","# Converting OGB sets to unique IDs sets\n","train_set = trainset_to_newset(train_set)\n","valid_set = valset_to_newset(valid_set)\n","test_set = valset_to_newset(test_set)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"yb0AjtQFXbAO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621189466471,"user_tz":-120,"elapsed":523619,"user":{"displayName":"Michael M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXS5G7Y8XOsAM2o7_7xf4XI_nDPbq0GP_tO4_J7g=s64","userId":"08878956878756496165"}},"outputId":"f185c64f-6abe-406c-8980-69fd569974a6"},"source":["!mkdir dataset/ogbl_biokg/standard_naming\n","\n","def write_dataset(name = \"test2id.txt\", dataset=\"test\"):\n","  with open(f'/content/AutoSF/dataset/ogbl_biokg/standard_naming/{name}', 'w') as f:\n","      # create the csv writer\n","      # write a row to the csv file\n","      writer = csv.writer(f, delimiter='\\t')\n","      writer.writerow([len(dataset['head'])])\n","\n","      for i, _ in enumerate(dataset['head']):\n","        writer.writerow([dataset['head'][i], dataset['tail'][i], dataset['relation'][i]])\n","\n","def create_dictionaries(dataset):\n","  with open(f'/content/AutoSF/dataset/ogbl_biokg/standard_naming/relation2id.txt', 'w') as f:\n","      writer = csv.writer(f, delimiter='\\t')\n","\n","      relation_set = set(dataset['relation'])\n","      writer.writerow([len(relation_set)])\n","      \n","      for i, _ in enumerate(relation_set):\n","        writer.writerow([i, i])\n","\n","  with open(f'/content/AutoSF/dataset/ogbl_biokg/standard_naming/entity2id.txt', 'w') as f:\n","      writer = csv.writer(f, delimiter='\\t')\n","\n","      entity_set = set(np.append(dataset['head'], dataset['tail']))\n","      writer.writerow([len(entity_set)])\n","      \n","      for i, _ in enumerate(entity_set):\n","        writer.writerow([i, i])\n","\n","create_dictionaries(train_set)\n","write_dataset(\"test2id.txt\", test_set)\n","write_dataset(\"train2id.txt\", train_set)\n","write_dataset(\"valid2id.txt\", valid_set)\n","\n","# Defining the Data Loader\n","loader = DataLoader('/content/AutoSF/dataset/ogbl_biokg/standard_naming/')"],"execution_count":24,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘dataset/ogbl_biokg/standard_naming’: File exists\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NI9_Entjrqm5"},"source":["# Option 1: Running the authors command\n","\n","The authors code does not work for our dataset.<br/>\n","Line 48 in train.py \n","<code>\n","valid_head_filter, valid_tail_filter, test_head_filter, test_tail_filter = loader.get_filter()\n","</code>  fills the RAM."]},{"cell_type":"code","metadata":{"id":"tcAgn9RVrtN2","executionInfo":{"status":"ok","timestamp":1621189466472,"user_tz":-120,"elapsed":523614,"user":{"displayName":"Michael M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXS5G7Y8XOsAM2o7_7xf4XI_nDPbq0GP_tO4_J7g=s64","userId":"08878956878756496165"}}},"source":["# Doesn't work, kills the RAM\n","# !python train.py --task_dir /content/AutoSF/dataset/ogbl_biokg/standard_naming/ --n_dim 128 --lr 0.5 --n_epoch 100 --n_batch 2048 --filter 0\n","\n","# Setting the option '--filter 0' would solve the problem, except the authors don't handle the option in their code"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z-KKsAjcrvbU"},"source":["# Option 2: Using the authors source code\n","\n","We modify the authors source code as to fit our dataset"]},{"cell_type":"code","metadata":{"id":"zU3jPUXKzm3T","executionInfo":{"status":"ok","timestamp":1621189466472,"user_tz":-120,"elapsed":523608,"user":{"displayName":"Michael M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXS5G7Y8XOsAM2o7_7xf4XI_nDPbq0GP_tO4_J7g=s64","userId":"08878956878756496165"}}},"source":["# Operating System\n","import os\n","\n","# Time\n","import time\n","\n","# tqdm\n","from tqdm import tqdm\n","\n","# PyTorch\n","import torch\n","import torch.nn as nn\n","from torch.optim import Adam, SGD, Adagrad\n","from torch.optim.lr_scheduler import ExponentialLR\n","import torch.multiprocessing as mp\n","\n","# AutoSF\n","from select_gpu import select_gpu\n","from utils import batch_by_size, cal_ranks, cal_performance\n","\n","# from base_model import BaseModel\n","from state import StateSpace\n","from predict import Predictor"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"KYni8xEp8vp5","executionInfo":{"status":"ok","timestamp":1621189466474,"user_tz":-120,"elapsed":523604,"user":{"displayName":"Michael M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXS5G7Y8XOsAM2o7_7xf4XI_nDPbq0GP_tO4_J7g=s64","userId":"08878956878756496165"}}},"source":["class KGEModule(nn.Module):\n","    def __init__(self, n_ent, n_rel, args, struct):\n","        super(KGEModule, self).__init__()\n","        self.n_ent = n_ent\n","        self.n_rel = n_rel\n","        self.args = args\n","        self.struct = struct\n","        self.lamb = args.lamb\n","        self.loss = torch.nn.Softplus().cuda()\n","        self.ent_embed = nn.Embedding(n_ent, args.n_dim)\n","        self.rel_embed = nn.Embedding(n_rel, args.n_dim)\n","        self.init_weight()\n","\n","    def init_weight(self):\n","        for param in self.parameters():\n","            nn.init.xavier_uniform_(param.data)\n","\n","    def forward(self, head, tail, rela, dropout=True):\n","        head = head.view(-1)\n","        tail = tail.view(-1)\n","        rela = rela.view(-1)\n","\n","        head_embed = self.ent_embed(head)\n","        tail_embed = self.ent_embed(tail)\n","        rela_embed = self.rel_embed(rela)\n","\n","        # get f = h' R t\n","\n","        pos_trip = self.test_trip(head_embed, rela_embed, tail_embed)\n","\n","        neg_tail = self.test_tail(head_embed, rela_embed)\n","        neg_head = self.test_head(rela_embed, tail_embed)\n","\n","        max_t = torch.max(neg_tail, 1, keepdim=True)[0]\n","        max_h = torch.max(neg_head, 1, keepdim=True)[0]\n","\n","        # multi-class loss: negative loglikelihood\n","        loss = - 2 * pos_trip + max_t + torch.log(torch.sum(torch.exp(neg_tail - max_t), 1)) + \\\n","               max_h + torch.log(torch.sum(torch.exp(neg_head - max_h), 1))\n","        self.regul = torch.sum(rela_embed ** 2)\n","\n","        return torch.sum(loss)\n","\n","    def forward_no_loss(self, head, tail, rela):\n","      head = head.view(-1)\n","      tail = tail.view(-1)\n","      rela = rela.view(-1)\n","\n","      head_embed = self.ent_embed(head)\n","      tail_embed = self.ent_embed(tail)\n","      rela_embed = self.rel_embed(rela)\n","\n","      return self.test_trip(head_embed, rela_embed, tail_embed)\n","\n","    def test_trip(self, head, rela, tail):\n","        vec_hr = self.get_hr(head, rela)\n","        scores = torch.sum(vec_hr * tail, 1)\n","        return scores\n","\n","    def test_tail(self, head, rela):\n","        vec_hr = self.get_hr(head, rela)\n","        tail_embed = self.ent_embed.weight\n","        scores = torch.mm(vec_hr, tail_embed.transpose(1, 0))\n","        return scores\n","\n","    def test_head(self, rela, tail):\n","        vec_rt = self.get_rt(rela, tail)\n","        head_embed = self.ent_embed.weight\n","        scores = torch.mm(vec_rt, head_embed.transpose(1, 0))\n","        return scores\n","\n","    def get_hr(self, head, rela):\n","        idx = tuple(self.struct)\n","        length = self.args.n_dim // 4\n","        h1 = head[:, :length]\n","        r1 = rela[:, :length]\n","\n","        h2 = head[:, 1 * length:2 * length]\n","        r2 = rela[:, 1 * length:2 * length]\n","\n","        h3 = head[:, 2 * length:3 * length]\n","        r3 = rela[:, 2 * length:3 * length]\n","\n","        h4 = head[:, 3 * length:4 * length]\n","        r4 = rela[:, 3 * length:4 * length]\n","\n","        hs = [h1, h2, h3, h4]\n","        rs = [r1, r2, r3, r4]\n","\n","        vs = [0, 0, 0, 0]\n","        vs[idx[0]] = h1 * r1\n","        vs[idx[1]] = h2 * r2\n","        vs[idx[2]] = h3 * r3\n","        vs[idx[3]] = h4 * r4\n","\n","        res_B = (len(idx) - 4) // 4\n","        for b_ in range(1, res_B + 1):\n","            base = 4 * b_\n","            vs[idx[base + 2]] += rs[idx[base + 0]] * hs[idx[base + 1]] * int(idx[base + 3])\n","        return torch.cat(vs, 1)\n","\n","    def get_rt(self, rela, tail):\n","        idx = tuple(self.struct)\n","        length = self.args.n_dim // 4\n","        t1 = tail[:, :length]\n","        r1 = rela[:, :length]\n","\n","        t2 = tail[:, 1 * length:2 * length]\n","        r2 = rela[:, 1 * length:2 * length]\n","\n","        t3 = tail[:, 2 * length:3 * length]\n","        r3 = rela[:, 2 * length:3 * length]\n","\n","        t4 = tail[:, 3 * length:4 * length]\n","        r4 = rela[:, 3 * length:4 * length]\n","\n","        ts = [t1, t2, t3, t4]\n","        rs = [r1, r2, r3, r4]\n","\n","        vs = [r1 * ts[idx[0]], r2 * ts[idx[1]], r3 * ts[idx[2]], r4 * ts[idx[3]]]\n","\n","        res_B = (len(idx) - 4) // 4\n","        for b_ in range(1, res_B + 1):\n","            base = 4 * b_\n","            vs[idx[base + 1]] += rs[idx[base + 0]] * ts[idx[base + 2]] * int(idx[base + 3])\n","        return torch.cat(vs, 1)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"G4vRXwE89B8h","executionInfo":{"status":"ok","timestamp":1621189466974,"user_tz":-120,"elapsed":524098,"user":{"displayName":"Michael M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXS5G7Y8XOsAM2o7_7xf4XI_nDPbq0GP_tO4_J7g=s64","userId":"08878956878756496165"}}},"source":["class BaseModel(object):\n","    def __init__(self, n_ent, n_rel, args, struct):\n","        self.model = KGEModule(n_ent, n_rel, args, struct)\n","        self.model.cuda()\n","\n","        self.n_ent = n_ent\n","        self.n_rel = n_rel\n","        self.time_tot = 0\n","        self.args = args\n","\n","    def train(self, train_data, tester_val, tester_tst):\n","        head, tail, rela = train_data\n","        # useful information related to cache\n","        n_train = len(head)\n","\n","        if self.args.optim=='adam' or self.args.optim=='Adam':\n","            self.optimizer = Adam(self.model.parameters(), lr=self.args.lr)\n","        elif self.args.optim=='adagrad' or self.args.optim=='Adagrad':\n","            self.optimizer = Adagrad(self.model.parameters(), lr=self.args.lr)\n","        else:\n","            self.optimizer = SGD(self.model.parameters(), lr=self.args.lr)\n","\n","        scheduler = ExponentialLR(self.optimizer, self.args.decay_rate)\n","\n","        n_epoch = self.args.n_epoch\n","        n_batch = self.args.n_batch\n","        best_mrr = 0\n","\n","        # used for counting repeated triplets for margin based loss\n","\n","        for epoch in range(n_epoch):\n","            start = time.time()\n","\n","            self.epoch = epoch\n","            rand_idx = torch.randperm(n_train)\n","            head = head[rand_idx].cuda()\n","            tail = tail[rand_idx].cuda()\n","            rela = rela[rand_idx].cuda()\n","\n","            epoch_loss = 0\n","\n","            for h, t, r in batch_by_size(n_batch, head, tail, rela, n_sample=n_train):\n","                self.model.zero_grad()\n","\n","                loss = self.model.forward(h, t, r)\n","                loss += self.args.lamb * self.model.regul\n","                loss.backward()\n","                self.optimizer.step()\n","                self.prox_operator()\n","                epoch_loss += loss.data.cpu().numpy()\n","\n","            self.time_tot += time.time() - start\n","            scheduler.step()\n","\n","            print(f\"Loss at Epoch {epoch}:   {epoch_loss}\")\n","\n","            if (epoch+1) %  self.args.epoch_per_test == 0:\n","                # output performance \n","                valid_mrr, valid_mr, valid_1, valid_10 = tester_val()\n","                test_mrr,  test_mr,  test_1,  test_10  = tester_tst()\n","                out_str = '$valid mrr:%.4f, H@1:%.4f, H@10:%.4f\\t\\t$test mrr:%.4f, H@1:%.4f, H@10:%.4f\\n'%(valid_mrr, valid_1, valid_10, test_mrr, test_1, test_10)\n","                if not self.args.mode == 'search':\n","                    print(out_str)\n","\n","                # output the best performance info\n","                if valid_mrr > best_mrr:\n","                    best_mrr = valid_mrr\n","                    best_str = out_str\n","                    torch.save(model.model.state_dict(), f'mrr_{best_mrr}_model.pth')\n","                    \n","                if best_mrr < self.args.thres:\n","                    print('\\tearly stopped in Epoch:{}, best_mrr:{}'.format(epoch+1, best_mrr), self.model.struct)\n","                    return best_mrr, best_str\n","        return best_mrr, best_str\n","\n","    def prox_operator(self,):\n","        for n, p in self.model.named_parameters():\n","            if 'ent' in n:\n","                X = p.data.clone()\n","                Z = torch.norm(X, p=2, dim=1, keepdim=True)\n","                Z[Z<1] = 1\n","                X = X/Z\n","                p.data.copy_(X.view(self.n_ent, -1))\n","\n","    def test_link(self, test_data, head_filter, tail_filter):\n","        heads, tails, relas = test_data\n","        batch_size = self.args.test_batch_size\n","        num_batch = len(heads) // batch_size + int(len(heads)%batch_size>0)\n","\n","        head_probs = []\n","        tail_probs = []\n","        for i in range(num_batch):\n","            start = i * batch_size\n","            end = min( (i+1)*batch_size, len(heads))\n","            batch_h = heads[start:end].cuda()\n","            batch_t = tails[start:end].cuda()\n","            batch_r = relas[start:end].cuda()\n","\n","            h_embed = self.model.ent_embed(batch_h)\n","            r_embed = self.model.rel_embed(batch_r)\n","            t_embed = self.model.ent_embed(batch_t)\n","\n","            head_scores = torch.sigmoid(self.model.test_head(r_embed, t_embed)).data\n","            tail_scores = torch.sigmoid(self.model.test_tail(h_embed, r_embed)).data\n","\n","            head_probs.append(head_scores.data.cpu().numpy())\n","            tail_probs.append(tail_scores.data.cpu().numpy())\n","\n","        head_probs = np.concatenate(head_probs) * head_filter\n","        tail_probs = np.concatenate(tail_probs) * tail_filter\n","        head_ranks = cal_ranks(head_probs, label=heads.data.numpy())\n","        tail_ranks = cal_ranks(tail_probs, label=tails.data.numpy())\n","        h_mrr, h_mr, h_h1, h_h10 = cal_performance(head_ranks)\n","        t_mrr, t_mr, t_h1, t_h10 = cal_performance(tail_ranks)\n","        mrr = (h_mrr + t_mrr) / 2\n","        mr = (h_mr + t_mr) / 2\n","        h1  = (h_h1  + t_h1 ) / 2\n","        h10 = (h_h10 + t_h10) / 2\n","        return mrr, mr, h1, h10"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"CGkD7y3e0h00","executionInfo":{"status":"ok","timestamp":1621189466974,"user_tz":-120,"elapsed":524092,"user":{"displayName":"Michael M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXS5G7Y8XOsAM2o7_7xf4XI_nDPbq0GP_tO4_J7g=s64","userId":"08878956878756496165"}}},"source":["# Model arguments (dimension of embeddings)\n","class ProgramArguments:\n","  def __init__(self, optim='adagrad', lamb=0.2, decay_rate=1.0, n_dim=1000, parrel=1, lr=0.1, thres=0.0, n_epoch=100, n_batch=2048, epoch_per_test=10, test_batch_size=100, mode='search'):\n","    self.optim = optim\n","    self.lamb = lamb \n","    self.decay_rate = decay_rate\n","    self.n_dim = n_dim\n","    self.parrel = parrel\n","    self.lr = lr\n","    self.thres = thres\n","    self.n_epoch = n_epoch\n","    self.n_batch = n_batch\n","    self.epoch_per_test = epoch_per_test\n","    self.test_batch_size = test_batch_size\n","    self.perf_file = None\n","    self.mode = mode\n","\n","\n","args = ProgramArguments()\n","\n","# Function to get MRR\n","def evaluate(eval_set, model):\n","  \"\"\"Returns the MRR on the given set plus 3 dummy variables\"\"\"\n","  # OGB Evaluator\n","  evaluator = Evaluator('ogbl-biokg')\n","\n","  # Loading test / evaluation data as (h,t,r) and (h',t',r) triplets\n","  heads, tails, relations = eval_set['head'], eval_set['tail'], eval_set['relation']\n","  heads_n, tails_n = eval_set['head_neg'], eval_set['tail_neg']\n","\n","  # Conversion to PyTorch tensors and in cuda memory\n","  # heads, tails, relations = torch.tensor(heads).cuda(), torch.tensor(tails).cuda(), torch.tensor(relations).cuda()\n","  # heads_n, tails_n = torch.tensor(heads_n).cuda(), torch.tensor(tails_n).cuda()\n","\n","  # print(heads.shape, tails.shape, relations.shape, heads_n.shape, tails_n.shape)\n","\n","  # Getting predictions on test / evaluation set\n","  # model(heads, tails, heads_n, tails_n, relations) # Is this allowed ???\n","  counter = 0\n","  y_pred_pos, y_pred_neg = [], []\n","  print(\"Model evaluation: Collecting scores\")\n","  for h, t, r, hs_n, ts_n in tqdm(zip(heads, tails, relations, heads_n, tails_n), total=len(heads)):\n","    h = torch.tensor([h]).cuda()\n","    t = torch.tensor([t]).cuda()\n","    r = torch.tensor([r]).cuda()\n","    r_n = torch.tensor(500 * [r]).cuda()\n","    h_n = torch.tensor(hs_n).cuda().view(-1)\n","    t_n = torch.tensor(ts_n).cuda().view(-1)\n","    \n","    with torch.no_grad():\n","      y_pos = model.forward_no_loss(h, t, r)\n","      y_neg = model.forward_no_loss(h_n, t_n, r)\n","      y_pred_pos.append(y_pos.cpu().numpy()[0])\n","      y_pred_neg.append(y_neg.cpu().numpy())\n","      \n","  # Evaluating predictions\n","  print(\"Model evaluation: Getting MRR\")\n","  metrics = evaluator.eval({\n","      'y_pred_pos': np.array(y_pred_pos), # Predictions on the actual facts\n","      'y_pred_neg': np.array(y_pred_neg),    # Predictions on the corrupted facts\n","  })\n","\n","  mrr = metrics['mrr_list'].mean()\n","  print(f\"Model evaluation: MRR is {mrr}\")\n","  return mrr, 0, 0, 0\n","\n","\n","def get_eval_fn(eval_set, model):\n","  def f():\n","    return evaluate(eval_set, model)\n","  return f"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"AcGHdMgnZK38","executionInfo":{"status":"ok","timestamp":1621189468211,"user_tz":-120,"elapsed":525323,"user":{"displayName":"Michael M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXS5G7Y8XOsAM2o7_7xf4XI_nDPbq0GP_tO4_J7g=s64","userId":"08878956878756496165"}}},"source":["# Finding current device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Getting infos from Data Loader\n","n_ent, n_rel = loader.graph_size()\n","\n","train_data = loader.load_data('train') # [[heads], [tails], [relations]] (4'762'677 triplets)\n","valid_data = loader.load_data('valid') # [[heads], [tails], [relations]] (  162'886 triplets)\n","test_data = loader.load_data('test')   # [[heads], [tails], [relations]] (  162'870 triplets)\n","\n","n_train = len(train_data[0])\n","\n","# This command kills the RAM\n","# valid_head_filter, valid_tail_filter, test_head_filter, test_tail_filter = loader.get_filter()\n","\n","train_data = [torch.LongTensor(vec).to(device) for vec in train_data]\n","valid_data = [torch.LongTensor(vec).to(device) for vec in valid_data]\n","test_data  = [torch.LongTensor(vec).to(device) for vec in test_data]"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"UdGTgydp62ru","executionInfo":{"status":"ok","timestamp":1621189468211,"user_tz":-120,"elapsed":525317,"user":{"displayName":"Michael M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhXS5G7Y8XOsAM2o7_7xf4XI_nDPbq0GP_tO4_J7g=s64","userId":"08878956878756496165"}}},"source":["directory = 'results'\n","if not os.path.exists(directory):\n","    os.makedirs(directory)\n","\n","\n","def run_model(i, state):\n","    print('newID:', i, state, len(state))\n","    args.perf_file = os.path.join(directory, 'biokg_perf.txt')\n","    torch.cuda.empty_cache()\n","    # sleep to avoid multiple gpu occupy\n","    time.sleep(10 * (i % args.parrel) + 1)\n","    # torch.cuda.set_device(device)\n","    torch.cuda.set_device(0)\n","\n","    model = BaseModel(n_ent, n_rel, args, state)\n","\n","    # (delete these 2 lines)\n","    evaluate(valid_set, model.model)\n","\n","    # This is the authors original code. Kills the RAM\n","    # tester_val = lambda: model.test_link(valid_data, valid_head_filter, valid_tail_filter)\n","    # tester_tst = lambda: model.test_link(test_data, test_head_filter, test_tail_filter)\n","    # best_mrr, best_str = model.train(train_data, tester_val, tester_tst)\n","\n","    # Our adaptation\n","    validate_fn = get_eval_fn(valid_set, model.model)\n","    test_fn = get_eval_fn(test_set, model.model)\n","    best_mrr, best_str = model.train(train_data, validate_fn, test_fn)\n","\n","    # Storing model\n","    \n","\n","    with open(args.perf_file, 'a') as f:\n","        print('ID:', i, 'structure:%s' % (str(state)), '\\tvalid mrr', best_mrr)\n","        for s in state:\n","            f.write(str(s) + ' ')\n","        f.write('\\t\\tbest_performance: ' + best_str)\n","    torch.cuda.empty_cache()\n","\n","    print(f\"Process {i} returned\")\n","    return best_mrr"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"EdrkuuTDamS-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e28b239b-4253-459c-8391-ac07d686882e"},"source":["# Main Program\n","os.environ[\"OMP_NUM_THREADS\"] = \"5\"\n","os.environ[\"MKL_NUM_THREADS\"] = \"5\"\n","\n","try:\n","    # mp.set_start_method('forkserver')\n","    pass\n","except RuntimeError:\n","    print(\"Multi-Processing context was already set\")\n","\n","state_obj = StateSpace()\n","T = 32  # train for 1000 iterations\n","N = 8  # number of states for train\n","NUM_STATES = 256  # number of states for predict\n","N_PREDS = 5\n","\n","# config predictor\n","pred_obj = [Predictor() for i in range(N_PREDS)]\n","\n","perf_file = os.path.join(directory, 'biokg_perf.txt')\n","\n","for B in [4, 6, 8, 10, 12, 14, 16]:\n","    best_score = 0\n","    num_train = 0\n","\n","    time_train = 0\n","    time_filt = 0\n","    time_pred = 0\n","    if B == 4:\n","        # only five candidates which worth evaluation in f^4\n","        TT = 1\n","    else:\n","        TT = T\n","    for t in range(TT):\n","        states_cand = []\n","        matrix_cand = []\n","        t_filt = time.time()\n","        counts = 0\n","        for i in range(NUM_STATES):\n","            state, matrix, count = state_obj.gen_new_state(B, matrix_cand)\n","            if state is not None:\n","                states_cand.append(state)\n","                matrix_cand.append(tuple(matrix))\n","            counts += count\n","        print('B=%d Iter %d\\tsampled %d candidate state for evaluate' % (B, t + 1, len(states_cand)), counts)\n","        states_cand = np.array(states_cand)\n","        matrix_cand = np.array(matrix_cand)\n","        time_filt = time.time() - t_filt\n","\n","        t_pred = time.time()\n","        if len(states_cand) < N:\n","            states_train = states_cand\n","            matrix_train = matrix_cand\n","        else:\n","            scores = []\n","            features = []\n","            for state in states_cand:\n","                features.append(state_obj.state2srf(state))\n","                # features.append(state_obj.state2onehot(state))\n","            features = torch.FloatTensor(np.array(features))\n","            for m in range(N_PREDS):\n","                scores.append(pred_obj[m].get_scores(features))\n","            scores = np.mean(np.array(scores), 0)\n","            top_k = scores.argsort()[-N:][::-1]\n","            states_train = np.array(states_cand[top_k])\n","            matrix_train = np.array(matrix_cand[top_k])\n","            print('top_k states selected', scores[top_k], time.time() - t_pred)\n","        time_pred += time.time() - t_pred\n","        # train the selected N models in parallel\n","        scores = []\n","        t_train = time.time()\n","        # pool = mp.Pool(processes=args.parrel)\n","        for i, state in enumerate(states_train):\n","            # score = pool.apply_async(run_model, (num_train, state,))\n","            score = run_model(num_train, state)\n","            num_train += 1\n","            scores.append(score)\n","        # pool.close()\n","        # pool.join()\n","        print('~~~~~~~~~~~~~~ parallelly train B=%d finished~~~~~~~~~~~~~~ ' % (B), t)\n","        time_train += time.time() - t_train\n","\n","        for state, matrix, score in zip(states_train, matrix_train, scores):\n","            scor = score.get()\n","            if scor > best_score:\n","                best_score = scor\n","            state_obj.history_matrix[(B - 4) // 2].append(tuple(matrix))\n","            state_obj.state_and_score[(B - 4) // 2].append((tuple(state), scor))\n","    state_obj.update_good((B - 4) // 2)\n","    print('number of models trained:', num_train, 'best score:', best_score)\n","\n","    t_pred = time.time()\n","    # train the predictor\n","    state_obj.update_train(perf_file)\n","    in_x = torch.from_numpy(np.array(state_obj.pred_x, dtype='float32'))\n","    in_y = torch.from_numpy(np.array(state_obj.pred_y, dtype='float32'))\n","    idx = np.random.choice(in_y.size(0), 16)\n","    batch_size = max(in_y.size(0) // 8, 1)\n","    print('------------ start training predictor ------------', in_x.size(), in_y.size())\n","    for m in range(N_PREDS):\n","        n = in_y.size(0)\n","        idx = np.random.choice(n, n * 4 // N_PREDS)\n","        pred_obj[m].train(in_x[idx], in_y[idx], batch_size, 0.3, n_iter=200 * (m + 1))\n","    print('\\t............ train predictor finished ............')\n","    time_pred += time.time() - t_pred\n","\n","    print('time used:', time_train, time_filt, time_pred, B, t)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["B=4 Iter 1\tsampled 5 candidate state for evaluate 12856\n","newID: 0 [0 1 2 3] 4\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|          | 1/162886 [00:00<5:22:08,  8.43it/s]"],"name":"stderr"},{"output_type":"stream","text":["Model evaluation: Collecting scores\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 162886/162886 [17:44<00:00, 153.01it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Model evaluation: Getting MRR\n","Model evaluation: MRR is 0.01333604846149683\n","Loss at Epoch 0:   183971255438.0\n","Loss at Epoch 1:   161477001748.0\n","Loss at Epoch 2:   153572131130.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YIHWqixLWbB2"},"source":["torch.save(model.model.state_dict(), f'mrr_{best_mrr}_model.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5tW3EFrEW3c4"},"source":["import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BwkKD_W3X0ly"},"source":["os.getcwd()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rGhkJ0BTX1gw"},"source":["!pwd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dF8NMS11X7eq"},"source":[""],"execution_count":null,"outputs":[]}]}