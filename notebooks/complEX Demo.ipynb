{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"complEX Demo.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qzkD4ZFhrnHR"},"source":["<center><h1> ComplEX - Variable Negative Training Samples </h1></center>"]},{"cell_type":"markdown","metadata":{"id":"w9I52p0EgoyZ"},"source":["# Open Graph Benchmark Library (OGBL) - BioKG\n","\n","<b>Graph</b> : The ogbl-biokg dataset is a Knowledge Graph (KG), which we created using data from a large number of biomedical data repositories. It contains 5 types of entities: diseases (10,687 nodes), proteins (17,499), drugs (10,533 nodes), side effects (9,969 nodes), and protein functions (45,085 nodes). There are 51 types of directed relations connecting two types of entities, including 39 kinds of drug-drug interactions, 8 kinds of protein-protein interaction, as well as drug-protein, drug-side effect, drug-protein, function-function relations. All relations are modeled as directed edges, among which the relations connecting the same entity types (e.g., protein-protein, drug-drug, function-function) are always symmetric, i.e., the edges are bi-directional.\n","\n","This dataset is relevant to both biomedical and fundamental ML research. On the biomedical side, the dataset allows us to get better insights into human biology and generate predictions that can guide downstream biomedical research. On the fundamental ML side, the dataset presents challenges in handling a noisy, incomplete KG with possible contradictory observations. This is because the ogbl-biokg dataset involves heterogeneous interactions that span from the molecular scale (e.g., protein-protein interactions within a cell) to whole populations (e.g., reports of unwanted side effects experienced by patients in a particular country). Further, triplets in the KG come from sources with a variety of confidence levels, including experimental readouts, human-curated annotations, and automatically extracted metadata.\n","\n","<b>Prediction task</b>: The task is to predict new triplets given the training triplets. The evaluation protocol is exactly the same as ogbl-wikikg2, except that here we only consider ranking against entities of the same type. For instance, when corrupting head entities of the protein type, we only consider negative protein entities.\n","\n","<b>Dataset splitting</b>: For this dataset, we adopt a random split. While splitting the triplets according to time is an attractive alternative, we note that it is incredibly challenging to obtain accurate information as to when individual experiments and observations underlying the triplets were made. We strive to provide additional dataset splits in future versions of the OGB.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"E9za5eGPbrY7"},"source":["# Installing libraries (OGB & TorchKGE)\n","\n","The OGB (Open Graph Benchmark) library is used in this notebook to retrieve the knowledge graph and to evaluate our model.<br/>\n","The TorchKGE library is used to create our model."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"45X6AazwbjAa","executionInfo":{"status":"ok","timestamp":1621189882982,"user_tz":-120,"elapsed":22341,"user":{"displayName":"Brian Pulfer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWm8LAV0xhS2hOAFrXkLBjliAgeXOJGa7D5y_j=s64","userId":"13180070647482773057"}},"outputId":"de35f390-9105-49ed-c1ce-963962f56f05"},"source":["# Installing OBG to download dataset\n","!pip install ogb\n","\n","# Getting TorchKGE library\n","!git clone https://github.com/torchkge-team/torchkge.git\n","!mv /content/torchkge /content/torchkge_repo\n","!mv /content/torchkge_repo/torchkge /content/torchkge\n","!pip install -r /content/torchkge_repo/requirements_dev.txt"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting ogb\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/c5/20b1e4a5ff90ead06139ce1c2362474b97bb3a73ee0166eb37f2d3eb0dba/ogb-1.3.1-py3-none-any.whl (67kB)\n","\r\u001b[K     |████▉                           | 10kB 21.2MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 29.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 30kB 21.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 16.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 61kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 6.2MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.19.5)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.15.0)\n","Collecting outdated>=0.2.0\n","  Downloading https://files.pythonhosted.org/packages/fd/f6/95588d496e518355c33b389222c99069b1c6f2c046be64f400072fdc7cda/outdated-0.2.1-py3-none-any.whl\n","Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (4.41.1)\n","Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.1.5)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.8.1+cu101)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (0.22.2.post1)\n","Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.7/dist-packages (from ogb) (1.24.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from outdated>=0.2.0->ogb) (2.23.0)\n","Collecting littleutils\n","  Downloading https://files.pythonhosted.org/packages/4e/b1/bb4e06f010947d67349f863b6a2ad71577f85590180a935f60543f622652/littleutils-0.2.2.tar.gz\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->ogb) (2.8.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->ogb) (3.7.4.3)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->ogb) (1.0.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->outdated>=0.2.0->ogb) (2020.12.5)\n","Building wheels for collected packages: littleutils\n","  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for littleutils: filename=littleutils-0.2.2-cp37-none-any.whl size=7051 sha256=5eaa333dbbad78ed897ed870cc8e91f512ed4b8c17625ca9f0a9e7b053853130\n","  Stored in directory: /root/.cache/pip/wheels/53/16/9f/ac67d15c40243754fd73f620e1b9b6dedc20492ecc19a2bae1\n","Successfully built littleutils\n","Installing collected packages: littleutils, outdated, ogb\n","Successfully installed littleutils-0.2.2 ogb-1.3.1 outdated-0.2.1\n","Cloning into 'torchkge'...\n","remote: Enumerating objects: 3410, done.\u001b[K\n","remote: Counting objects: 100% (89/89), done.\u001b[K\n","remote: Compressing objects: 100% (37/37), done.\u001b[K\n","remote: Total 3410 (delta 54), reused 82 (delta 52), pack-reused 3321\u001b[K\n","Receiving objects: 100% (3410/3410), 794.66 KiB | 9.35 MiB/s, done.\n","Resolving deltas: 100% (2256/2256), done.\n","Collecting sphinx>=3.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/5b/50ccdef4683ffac13fdf4cc80fa9ced84849fd4eca444dec22e6c937a1e2/Sphinx-4.0.1-py3-none-any.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 15.0MB/s \n","\u001b[?25hCollecting sphinx_rtd_theme>=0.5.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/24/2475e8f83519b54b2148d4a56eb1111f9cec630d088c3ffc214492c12107/sphinx_rtd_theme-0.5.2-py2.py3-none-any.whl (9.1MB)\n","\u001b[K     |████████████████████████████████| 9.2MB 47.3MB/s \n","\u001b[?25hCollecting numpydoc>=1.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/1d/9e398c53d6ae27d5ab312ddc16a9ffe1bee0dfdf1d6ec88c40b0ca97582e/numpydoc-1.1.0-py3-none-any.whl (47kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n","\u001b[?25hCollecting flake8>=3.8.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/80/35a0716e5d5101e643404dabd20f07f5528a21f3ef4032d31a49c913237b/flake8-3.9.2-py2.py3-none-any.whl (73kB)\n","\u001b[K     |████████████████████████████████| 81kB 11.4MB/s \n","\u001b[?25hCollecting tox>=3.18\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/63/2fa635ac1b8a22e960654b07c270dfb53eb873aba261006536de40327b18/tox-3.23.1-py2.py3-none-any.whl (85kB)\n","\u001b[K     |████████████████████████████████| 92kB 11.1MB/s \n","\u001b[?25hCollecting pytest-runner>=5\n","  Downloading https://files.pythonhosted.org/packages/40/96/9024a1c07bbe5e16bdcbcbd021b608e37b32df4301ae2090aad27c24ffe6/pytest_runner-5.3.0-py3-none-any.whl\n","Collecting pytest>=5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/59/6821e900592fbe261f19d67e4def0cb27e52ef8ed16d9922c144961cc1ee/pytest-6.2.4-py3-none-any.whl (280kB)\n","\u001b[K     |████████████████████████████████| 286kB 54.0MB/s \n","\u001b[?25hCollecting pip>=20.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/6f/43037c7bcc8bd8ba7c9074256b1a11596daa15555808ec748048c1507f08/pip-21.1.1-py3-none-any.whl (1.5MB)\n","\u001b[K     |████████████████████████████████| 1.6MB 37.8MB/s \n","\u001b[?25hCollecting bumpversion>=0.6.0\n","  Downloading https://files.pythonhosted.org/packages/4e/ff/93f0db7b3ca337e9f2a289980083e858775dfb3672b38052c6911b36ea66/bumpversion-0.6.0-py2.py3-none-any.whl\n","Requirement already satisfied: wheel>=0.34.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/torchkge_repo/requirements_dev.txt (line 15)) (0.36.2)\n","Collecting sphinxcontrib-applehelp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/47/86022665a9433d89a66f5911b558ddff69861766807ba685de2e324bd6ed/sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121kB)\n","\u001b[K     |████████████████████████████████| 122kB 60.8MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.1->-r /content/torchkge_repo/requirements_dev.txt (line 2)) (20.9)\n","Collecting sphinxcontrib-devhelp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/09/5de5ed43a521387f18bdf5f5af31d099605c992fd25372b2b9b825ce48ee/sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84kB)\n","\u001b[K     |████████████████████████████████| 92kB 13.0MB/s \n","\u001b[?25hRequirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.1->-r /content/torchkge_repo/requirements_dev.txt (line 2)) (1.1.4)\n","Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.1->-r /content/torchkge_repo/requirements_dev.txt (line 2)) (2.9.1)\n","Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.1->-r /content/torchkge_repo/requirements_dev.txt (line 2)) (1.2.0)\n","Collecting MarkupSafe<2.0\n","  Downloading https://files.pythonhosted.org/packages/c2/37/2e4def8ce3739a258998215df907f5815ecd1af71e62147f5eea2d12d4e8/MarkupSafe-1.1.1-cp37-cp37m-manylinux2010_x86_64.whl\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.1->-r /content/torchkge_repo/requirements_dev.txt (line 2)) (56.1.0)\n","Requirement already satisfied: Jinja2<3.0,>=2.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.1->-r /content/torchkge_repo/requirements_dev.txt (line 2)) (2.11.3)\n","Collecting sphinxcontrib-qthelp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/14/05f9206cf4e9cfca1afb5fd224c7cd434dcc3a433d6d9e4e0264d29c6cdb/sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90kB)\n","\u001b[K     |████████████████████████████████| 92kB 12.5MB/s \n","\u001b[?25hCollecting sphinxcontrib-htmlhelp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/8222554b29b3acde8420128d6d3999c5904d40922ef4b6ccb370e2be7421/sphinxcontrib_htmlhelp-1.0.3-py2.py3-none-any.whl (96kB)\n","\u001b[K     |████████████████████████████████| 102kB 13.0MB/s \n","\u001b[?25hRequirement already satisfied: docutils<0.18,>=0.14 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.1->-r /content/torchkge_repo/requirements_dev.txt (line 2)) (0.17.1)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.1->-r /content/torchkge_repo/requirements_dev.txt (line 2)) (0.7.12)\n","Collecting sphinxcontrib-jsmath\n","  Downloading https://files.pythonhosted.org/packages/c2/42/4c8646762ee83602e3fb3fbe774c2fac12f317deb0b5dbeeedd2d3ba4b77/sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl\n","Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.1->-r /content/torchkge_repo/requirements_dev.txt (line 2)) (2.6.1)\n","Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.1->-r /content/torchkge_repo/requirements_dev.txt (line 2)) (2.1.0)\n","Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=3.1->-r /content/torchkge_repo/requirements_dev.txt (line 2)) (2.23.0)\n","Collecting pycodestyle<2.8.0,>=2.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/cc/227251b1471f129bc35e966bb0fceb005969023926d744139642d847b7ae/pycodestyle-2.7.0-py2.py3-none-any.whl (41kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from flake8>=3.8.3->-r /content/torchkge_repo/requirements_dev.txt (line 7)) (4.0.1)\n","Collecting pyflakes<2.4.0,>=2.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/11/2a745612f1d3cbbd9c69ba14b1b43a35a2f5c3c81cd0124508c52c64307f/pyflakes-2.3.1-py2.py3-none-any.whl (68kB)\n","\u001b[K     |████████████████████████████████| 71kB 9.7MB/s \n","\u001b[?25hCollecting mccabe<0.7.0,>=0.6.0\n","  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n","Requirement already satisfied: toml>=0.9.4 in /usr/local/lib/python3.7/dist-packages (from tox>=3.18->-r /content/torchkge_repo/requirements_dev.txt (line 8)) (0.10.2)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from tox>=3.18->-r /content/torchkge_repo/requirements_dev.txt (line 8)) (1.15.0)\n","Collecting pluggy>=0.12.0\n","  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n","Requirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from tox>=3.18->-r /content/torchkge_repo/requirements_dev.txt (line 8)) (3.0.12)\n","Requirement already satisfied: py>=1.4.17 in /usr/local/lib/python3.7/dist-packages (from tox>=3.18->-r /content/torchkge_repo/requirements_dev.txt (line 8)) (1.10.0)\n","Collecting virtualenv!=20.0.0,!=20.0.1,!=20.0.2,!=20.0.3,!=20.0.4,!=20.0.5,!=20.0.6,!=20.0.7,>=16.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/59/f8815ff01ac7eff0f628c454f2d2b4cace19b70ccc9dcdbc61c3eb7f599d/virtualenv-20.4.6-py2.py3-none-any.whl (7.2MB)\n","\u001b[K     |████████████████████████████████| 7.2MB 54.2MB/s \n","\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=5->-r /content/torchkge_repo/requirements_dev.txt (line 10)) (21.2.0)\n","Requirement already satisfied: iniconfig in /usr/local/lib/python3.7/dist-packages (from pytest>=5->-r /content/torchkge_repo/requirements_dev.txt (line 10)) (1.1.1)\n","Collecting bump2version\n","  Downloading https://files.pythonhosted.org/packages/1d/e3/fa60c47d7c344533142eb3af0b73234ef8ea3fb2da742ab976b947e717df/bump2version-1.0.1-py2.py3-none-any.whl\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->sphinx>=3.1->-r /content/torchkge_repo/requirements_dev.txt (line 2)) (2.4.7)\n","Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel>=1.3->sphinx>=3.1->-r /content/torchkge_repo/requirements_dev.txt (line 2)) (2018.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx>=3.1->-r /content/torchkge_repo/requirements_dev.txt (line 2)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx>=3.1->-r /content/torchkge_repo/requirements_dev.txt (line 2)) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx>=3.1->-r /content/torchkge_repo/requirements_dev.txt (line 2)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.5.0->sphinx>=3.1->-r /content/torchkge_repo/requirements_dev.txt (line 2)) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->flake8>=3.8.3->-r /content/torchkge_repo/requirements_dev.txt (line 7)) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->flake8>=3.8.3->-r /content/torchkge_repo/requirements_dev.txt (line 7)) (3.7.4.3)\n","Requirement already satisfied: appdirs<2,>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from virtualenv!=20.0.0,!=20.0.1,!=20.0.2,!=20.0.3,!=20.0.4,!=20.0.5,!=20.0.6,!=20.0.7,>=16.0.0->tox>=3.18->-r /content/torchkge_repo/requirements_dev.txt (line 8)) (1.4.4)\n","Collecting distlib<1,>=0.3.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/0a/490fa011d699bb5a5f3a0cf57de82237f52a6db9d40f33c53b2736c9a1f9/distlib-0.3.1-py2.py3-none-any.whl (335kB)\n","\u001b[K     |████████████████████████████████| 337kB 60.9MB/s \n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: sphinx-rtd-theme 0.5.2 has requirement docutils<0.17, but you'll have docutils 0.17.1 which is incompatible.\u001b[0m\n","\u001b[?25hInstalling collected packages: sphinxcontrib-applehelp, sphinxcontrib-devhelp, MarkupSafe, sphinxcontrib-qthelp, sphinxcontrib-htmlhelp, sphinxcontrib-jsmath, sphinx, sphinx-rtd-theme, numpydoc, pycodestyle, pyflakes, mccabe, flake8, pluggy, distlib, virtualenv, tox, pytest-runner, pytest, pip, bump2version, bumpversion\n","  Found existing installation: MarkupSafe 2.0.0\n","    Uninstalling MarkupSafe-2.0.0:\n","      Successfully uninstalled MarkupSafe-2.0.0\n","  Found existing installation: Sphinx 1.8.5\n","    Uninstalling Sphinx-1.8.5:\n","      Successfully uninstalled Sphinx-1.8.5\n","  Found existing installation: pluggy 0.7.1\n","    Uninstalling pluggy-0.7.1:\n","      Successfully uninstalled pluggy-0.7.1\n","  Found existing installation: pytest 3.6.4\n","    Uninstalling pytest-3.6.4:\n","      Successfully uninstalled pytest-3.6.4\n","  Found existing installation: pip 19.3.1\n","    Uninstalling pip-19.3.1:\n","      Successfully uninstalled pip-19.3.1\n","Successfully installed MarkupSafe-1.1.1 bump2version-1.0.1 bumpversion-0.6.0 distlib-0.3.1 flake8-3.9.2 mccabe-0.6.1 numpydoc-1.1.0 pip-21.1.1 pluggy-0.13.1 pycodestyle-2.7.0 pyflakes-2.3.1 pytest-6.2.4 pytest-runner-5.3.0 sphinx-4.0.1 sphinx-rtd-theme-0.5.2 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-1.0.3 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 tox-3.23.1 virtualenv-20.4.6\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["sphinxcontrib"]}}},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"mufW30DjbtZe"},"source":["# Imports"]},{"cell_type":"code","metadata":{"id":"yXf4nGQzrn05","executionInfo":{"status":"ok","timestamp":1621189884784,"user_tz":-120,"elapsed":22450,"user":{"displayName":"Brian Pulfer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWm8LAV0xhS2hOAFrXkLBjliAgeXOJGa7D5y_j=s64","userId":"13180070647482773057"}}},"source":["# General Purpose imports\n","import os\n","import sys\n","import json\n","import time\n","import tqdm\n","from copy import copy\n","\n","# Math / Data structures imports\n","import math\n","import numpy as np\n","import pandas as pd \n","import matplotlib.pyplot as plt\n","\n","# PyTorch imports\n","import torch                                                # PyTorch\n","from torch import cuda                                      # CUDA device\n","from torch.optim import Adam                                # Adam optimizer\n","from torch.utils.data import DataLoader\n","\n","# OGB Improts\n","from ogb.linkproppred import Evaluator                      # Evaluates model\n","from ogb.linkproppred.dataset import LinkPropPredDataset    # Loads KG \n","\n","# TorchKGE imports\n","import torchkge\n","from torchkge.utils.data import DataLoader as KGEDataLoader               # Loads batches\n","from torchkge.utils.losses import MarginLoss                # Loss function\n","from torchkge.models.bilinear import ComplExModel           # KGE Model\n","from torchkge.data_structures import KnowledgeGraph         # KG object\n","from torchkge.sampling import BernoulliNegativeSampler      # Corrupts triplets"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u7wtjqq-bx3e"},"source":["# Accessing data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tlfauBbmbzql","executionInfo":{"status":"ok","timestamp":1621190719437,"user_tz":-120,"elapsed":855103,"user":{"displayName":"Brian Pulfer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWm8LAV0xhS2hOAFrXkLBjliAgeXOJGa7D5y_j=s64","userId":"13180070647482773057"}},"outputId":"0980f8af-a729-4029-9d57-1c69d3a0954e"},"source":["dataset = LinkPropPredDataset(name = 'ogbl-biokg')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading http://snap.stanford.edu/ogb/data/linkproppred/biokg.zip\n"],"name":"stdout"},{"output_type":"stream","text":["Downloaded 0.90 GB: 100%|██████████| 920/920 [13:28<00:00,  1.14it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Extracting dataset/biokg.zip\n","Loading necessary files...\n","This might take a while.\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 2647.92it/s]"],"name":"stderr"},{"output_type":"stream","text":["Processing graphs...\n","Saving...\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8RaBk3ysHGsI","executionInfo":{"status":"ok","timestamp":1621190964226,"user_tz":-120,"elapsed":1090935,"user":{"displayName":"Brian Pulfer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWm8LAV0xhS2hOAFrXkLBjliAgeXOJGa7D5y_j=s64","userId":"13180070647482773057"}},"outputId":"e158b7a7-a759-439d-d7b2-eebc74d85fc4"},"source":["# Getting the dataset train-val-test split\n","split_set = dataset.get_edge_split()\n","train_set, valid_set, test_set = split_set[\"train\"], split_set[\"valid\"], split_set[\"test\"]\n","\n","#Re-indexing the dataset from (type, index) to (index)\n","# Getting the dataset train-val-test split\n","split_set = dataset.get_edge_split()\n","train_set, valid_set, test_set = split_set[\"train\"], split_set[\"valid\"], split_set[\"test\"]\n","\n","\n","def type_and_id_2_new_id(typ, id):\n","  base = 0\n","\n","  if 'dis' in typ:\n","    base = 0\n","  elif 'prot' in typ:\n","    base = 10_687\n","  elif 'drug' in typ:\n","    base = 10_687 + 17_499\n","  elif 'effe' in typ:\n","    base = 10_687 + 17_499 + 10_533\n","  elif 'fun' in typ:\n","    base = 10_687 + 17_499 + 10_533 + 9_969\n","\n","  return base + id\n","\n","def trainset_to_newset(train_set):\n","  tmp_set = []\n","\n","  for ht, h, r, tt, t in zip(train_set['head_type'], train_set['head'], train_set['relation'], train_set['tail_type'], train_set['tail']):\n","    head_id = type_and_id_2_new_id(ht, h)\n","    tail_id = type_and_id_2_new_id(tt, t)\n","  \n","    tmp_set.append([head_id, r, tail_id])\n","  \n","  return pd.DataFrame(np.array(tmp_set), columns=['head', 'relation', 'tail'])\n","\n","def valset_to_newset(val_set):\n","  tmp_set = []\n","\n","  for ht, h, nhs, r, tt, t, nts in zip(val_set['head_type'], val_set['head'], val_set['head_neg'], val_set['relation'], val_set['tail_type'], val_set['tail'], val_set['tail_neg']):\n","    h_id = type_and_id_2_new_id(ht, h)\n","    t_id = type_and_id_2_new_id(tt, t)\n","\n","    nh_ids, nt_ids = [], []\n","    for nh, nt in zip(nhs, nts):\n","      nh_id = type_and_id_2_new_id(ht, nh)\n","      nt_id = type_and_id_2_new_id(tt, nt)\n","\n","      nh_ids.append(nh_id)\n","      nt_ids.append(nt_id)\n","\n","    tmp_set.append([h_id, nh_ids, r, t_id, nt_ids])\n","  \n","  return pd.DataFrame(np.array(tmp_set), columns=['head', 'head_neg', 'relation', 'tail', 'tail_neg'])\n","  \n","train_set = trainset_to_newset(train_set)\n","valid_set = valset_to_newset(valid_set)\n","test_set = valset_to_newset(test_set)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"],"name":"stderr"},{"output_type":"stream","text":["          head  relation   tail\n","0         1718         0  13894\n","1         4903         0  24349\n","2         5480         0  26686\n","3         3148         0  17934\n","4        10300         0  26889\n","...        ...       ...    ...\n","4762673  24553        50  22370\n","4762674  21512        50  11344\n","4762675  23345        50  22686\n","4762676  22715        50  13169\n","4762677  12783        50  12780\n","\n","[4762678 rows x 3 columns]\n","Number of distinct entities:  93773\n","Number of distinct relations:  51\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bigv9RA1BNaR"},"source":["# Loading the model"]},{"cell_type":"code","metadata":{"id":"I24EkDkvOsfN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621191039300,"user_tz":-120,"elapsed":21148,"user":{"displayName":"Brian Pulfer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWm8LAV0xhS2hOAFrXkLBjliAgeXOJGa7D5y_j=s64","userId":"13180070647482773057"}},"outputId":"91d5fab6-86c6-41ef-fe35-a3525293b8c8"},"source":["from google.colab import drive\n","\n","# Mounting drive to store the best weights\n","drive.mount('/content/drive')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jsWUvvPJBNiM","executionInfo":{"status":"ok","timestamp":1621191612557,"user_tz":-120,"elapsed":1346,"user":{"displayName":"Brian Pulfer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWm8LAV0xhS2hOAFrXkLBjliAgeXOJGa7D5y_j=s64","userId":"13180070647482773057"}}},"source":["model = torch.load('/content/drive/MyDrive/best_model_weights.pth')\n","\n","if cuda.is_available():\n","  model.cuda()"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JuA5X56pXe6y"},"source":["# Real Fact Evaluation\n","\n","In this example test, we go through all training facts (h, t, r) and corrupt them (h', t', r) and see how many time the scoring for the actual facts are higher, i.e. f(h, t, r) > f(h', t', r). This gives a sort of training accuracy."]},{"cell_type":"code","metadata":{"id":"-vgHfh4XbgYo","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1621191094279,"user_tz":-120,"elapsed":560,"user":{"displayName":"Brian Pulfer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWm8LAV0xhS2hOAFrXkLBjliAgeXOJGa7D5y_j=s64","userId":"13180070647482773057"}},"outputId":"7b042e5c-aa43-4b27-c4f4-6ba0ab195410"},"source":["df_train"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>head</th>\n","      <th>relation</th>\n","      <th>tail</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1718</td>\n","      <td>0</td>\n","      <td>13894</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4903</td>\n","      <td>0</td>\n","      <td>24349</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5480</td>\n","      <td>0</td>\n","      <td>26686</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3148</td>\n","      <td>0</td>\n","      <td>17934</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10300</td>\n","      <td>0</td>\n","      <td>26889</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4762673</th>\n","      <td>24553</td>\n","      <td>50</td>\n","      <td>22370</td>\n","    </tr>\n","    <tr>\n","      <th>4762674</th>\n","      <td>21512</td>\n","      <td>50</td>\n","      <td>11344</td>\n","    </tr>\n","    <tr>\n","      <th>4762675</th>\n","      <td>23345</td>\n","      <td>50</td>\n","      <td>22686</td>\n","    </tr>\n","    <tr>\n","      <th>4762676</th>\n","      <td>22715</td>\n","      <td>50</td>\n","      <td>13169</td>\n","    </tr>\n","    <tr>\n","      <th>4762677</th>\n","      <td>12783</td>\n","      <td>50</td>\n","      <td>12780</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4762678 rows × 3 columns</p>\n","</div>"],"text/plain":["          head  relation   tail\n","0         1718         0  13894\n","1         4903         0  24349\n","2         5480         0  26686\n","3         3148         0  17934\n","4        10300         0  26889\n","...        ...       ...    ...\n","4762673  24553        50  22370\n","4762674  21512        50  11344\n","4762675  23345        50  22686\n","4762676  22715        50  13169\n","4762677  12783        50  12780\n","\n","[4762678 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"J3oa768yjwOr"},"source":["# Checking that the first triplet in training set has higher score than any random triplet"]},{"cell_type":"code","metadata":{"id":"OtWRbBXrcX7W","executionInfo":{"status":"ok","timestamp":1621191811767,"user_tz":-120,"elapsed":653,"user":{"displayName":"Brian Pulfer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWm8LAV0xhS2hOAFrXkLBjliAgeXOJGa7D5y_j=s64","userId":"13180070647482773057"}}},"source":["\n","head = torch.LongTensor([1718]).cuda()\n","tail = torch.LongTensor([13894]).cuda()\n","relations = torch.LongTensor([0]).cuda()\n","negative_heads = torch.LongTensor([1718]).cuda()\n","negative_tails = torch.LongTensor([1]).cuda()\n","\n","y_pos, y_neg = model(\n","    head,\n","    tail,\n","    negative_heads,\n","    negative_tails,\n","    relations\n",")"],"execution_count":58,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2B0VF_vZieN5","executionInfo":{"status":"ok","timestamp":1621191812937,"user_tz":-120,"elapsed":736,"user":{"displayName":"Brian Pulfer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhWm8LAV0xhS2hOAFrXkLBjliAgeXOJGa7D5y_j=s64","userId":"13180070647482773057"}},"outputId":"3455a8ca-c144-4d6e-b862-be895045fe71"},"source":["y_pos.item(), y_neg.item()"],"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3.067988395690918, -0.7393243908882141)"]},"metadata":{"tags":[]},"execution_count":59}]}]}